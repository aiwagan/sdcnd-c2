{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import with_statement #for python 2.5\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "import scipy.misc\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "LOGDIR = './save'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "\n",
    "#points to the end of the last batch\n",
    "train_batch_pointer = 0\n",
    "val_batch_pointer = 0\n",
    "\n",
    "#read data.txt\n",
    "with open(\"/home/aiwagan/challenge2/challenge2.csv\") as f:\n",
    "    for line in f:\n",
    "        xs.append(\"/home/aiwagan/output/\" + line.split()[0])\n",
    "        #the paper by Nvidia uses the inverse of the turning radius,\n",
    "        #but steering wheel angle is proportional to the inverse of turning radius\n",
    "        #so the steering wheel angle in radians is used as the output\n",
    "        ys.append(float(line.split()[1]) * scipy.pi / 180)\n",
    "\n",
    "\n",
    "#get number of images\n",
    "num_images = len(xs)\n",
    "\n",
    "#shuffle list of images\n",
    "c = list(zip(xs, ys))\n",
    "random.shuffle(c)\n",
    "xs, ys = zip(*c)\n",
    "\n",
    "\n",
    "train_xs = xs[:int(len(xs) * 0.8)]\n",
    "train_ys = ys[:int(len(xs) * 0.8)]\n",
    "\n",
    "val_xs = xs[-int(len(xs) * 0.2):]\n",
    "val_ys = ys[-int(len(xs) * 0.2):]\n",
    "\n",
    "num_train_images = len(train_xs)\n",
    "num_val_images = len(val_xs)\n",
    "\n",
    "def LoadTrainBatch(batch_size):\n",
    "    global train_batch_pointer\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(0, batch_size):\n",
    "        x_out.append((scipy.misc.imread(train_xs[(train_batch_pointer + i) % num_train_images])[-150:]) / 255.0)\n",
    "        y_out.append([train_ys[(train_batch_pointer + i) % num_train_images]])\n",
    "    train_batch_pointer += batch_size\n",
    "    return x_out, y_out\n",
    "\n",
    "def LoadValBatch(batch_size):\n",
    "    global val_batch_pointer\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(0, batch_size):\n",
    "        x_out.append((scipy.misc.imread(val_xs[(val_batch_pointer + i) % num_val_images])[-150:] )/ 255.0)\n",
    "        y_out.append([val_ys[(val_batch_pointer + i) % num_val_images]])\n",
    "    val_batch_pointer += batch_size\n",
    "    return x_out, y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14131"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_val_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W, stride):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='VALID')\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 120, 160, 3])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "x_image = x\n",
    "\n",
    "#first convolutional layer\n",
    "W_conv1 = weight_variable([5, 5, 3, 24])\n",
    "b_conv1 = bias_variable([24])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1, 2) + b_conv1)\n",
    "#print h_conv1.get_shape()\n",
    "#second convolutional layer\n",
    "W_conv2 = weight_variable([5, 5, 24, 36])\n",
    "b_conv2 = bias_variable([36])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2, 2) + b_conv2)\n",
    "#print h_conv2.get_shape()\n",
    "#third convolutional layer\n",
    "W_conv3 = weight_variable([5, 5, 36, 48])\n",
    "b_conv3 = bias_variable([48])\n",
    "\n",
    "h_conv3 = tf.nn.relu(conv2d(h_conv2, W_conv3, 2) + b_conv3)\n",
    "#print h_conv3.get_shape()\n",
    "#fourth convolutional layer\n",
    "W_conv4 = weight_variable([5, 5, 48, 64])\n",
    "b_conv4 = bias_variable([64])\n",
    "\n",
    "h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4, 1) + b_conv4)\n",
    "#print h_conv4.get_shape()\n",
    "#fifth convolutional layer\n",
    "W_conv5 = weight_variable([8, 8, 64, 64])\n",
    "b_conv5 = bias_variable([64])\n",
    "\n",
    "h_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5, 1) + b_conv5)\n",
    "#print h_conv5.get_shape()\n",
    "\n",
    "#FCL 1\n",
    "W_fc1 = weight_variable([384, 1164])\n",
    "b_fc1 = bias_variable([1164])\n",
    "\n",
    "h_conv5_flat = tf.reshape(h_conv5, [-1, 384])\n",
    "#print h_conv5_flat.get_shape()\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_conv5_flat, W_fc1) + b_fc1)\n",
    "#print h_fc1.get_shape()\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "#print h_fc1_drop.get_shape()\n",
    "#FCL 2\n",
    "W_fc2 = weight_variable([1164, 100])\n",
    "b_fc2 = bias_variable([100])\n",
    "\n",
    "h_fc2 = tf.nn.relu(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "#print h_fc2.get_shape()\n",
    "h_fc2_drop = tf.nn.dropout(h_fc2, keep_prob)\n",
    "#print h_fc1_drop.get_shape()\n",
    "#FCL 3\n",
    "W_fc3 = weight_variable([100, 50])\n",
    "b_fc3 = bias_variable([50])\n",
    "\n",
    "h_fc3 = tf.nn.relu(tf.matmul(h_fc2_drop, W_fc3) + b_fc3)\n",
    "\n",
    "h_fc3_drop = tf.nn.dropout(h_fc3, keep_prob)\n",
    "\n",
    "#FCL 3\n",
    "W_fc4 = weight_variable([50, 10])\n",
    "b_fc4 = bias_variable([10])\n",
    "\n",
    "h_fc4 = tf.nn.relu(tf.matmul(h_fc3_drop, W_fc4) + b_fc4)\n",
    "\n",
    "h_fc4_drop = tf.nn.dropout(h_fc4, keep_prob)\n",
    "\n",
    "#Output\n",
    "W_fc5 = weight_variable([10, 1])\n",
    "b_fc5 = bias_variable([1])\n",
    "\n",
    "y = tf.mul(tf.atan(tf.matmul(h_fc4_drop, W_fc5) + b_fc5), 2) #scale the atan output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(tf.sub(y_, y)))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, val loss 0.251598\n",
      "Model saved in file: ./save/model.ckpt\n",
      "step 10, val loss 0.0347271\n",
      "step 20, val loss 0.0351791\n",
      "step 30, val loss 0.0364182\n",
      "step 40, val loss 0.0328997\n",
      "step 50, val loss 0.0284427\n",
      "step 60, val loss 0.0257319\n",
      "step 70, val loss 0.0208793\n",
      "step 80, val loss 0.016932\n",
      "step 90, val loss 0.0118199\n",
      "step 100, val loss 0.00977855\n",
      "Model saved in file: ./save/model.ckpt\n",
      "step 110, val loss 0.00843852\n",
      "step 120, val loss 0.00826085\n"
     ]
    }
   ],
   "source": [
    "#train over the dataset about 30 times\n",
    "for i in range(int(num_images * 0.3)):\n",
    "    xs, ys = LoadTrainBatch(100)\n",
    "    train_step.run(feed_dict={x: xs, y_: ys, keep_prob: 0.8})\n",
    "    if i % 10 == 0:\n",
    "        xs, ys = LoadValBatch(100)\n",
    "        print(\"step %d, val loss %g\"%(i, loss.eval(feed_dict={x:xs, y_: ys, keep_prob: 1.0})))\n",
    "    if i % 100 == 0:\n",
    "        if not os.path.exists(LOGDIR):\n",
    "            os.makedirs(LOGDIR)\n",
    "        checkpoint_path = os.path.join(LOGDIR, \"model.ckpt\")\n",
    "        filename = saver.save(sess, checkpoint_path)\n",
    "        print(\"Model saved in file: %s\" % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Testing component Code\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
